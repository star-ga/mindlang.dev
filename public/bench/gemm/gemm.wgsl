// GEMM Benchmark - Compiled WGSL Shader
// Generated by MIND Compiler v0.1.0
// Copyright (c) 2026 STARGA Inc. - MIT License
//
// Register-tiled matrix multiplication.
// 16x16 workgroups, 4x4 output per thread = 64x64 output per workgroup.
// Shared memory double-buffered tile loads with coalesced access.

struct GemmParams {
    M: u32,
    N: u32,
    K: u32,
    alpha: f32,
}

@group(0) @binding(0) var<uniform> params: GemmParams;
@group(0) @binding(1) var<storage, read> A: array<f32>;
@group(0) @binding(2) var<storage, read> B: array<f32>;
@group(0) @binding(3) var<storage, read_write> C: array<f32>;

// Tile dimensions: 64x64 output, 16-deep K tiles
// Shared memory: 64x16 for A tile + 16x64 for B tile = 8 KB total
var<workgroup> sa: array<f32, 1024>;  // 64 rows x 16 cols
var<workgroup> sb: array<f32, 1024>;  // 16 rows x 64 cols

@compute @workgroup_size(16, 16, 1)
fn main(@builtin(local_invocation_id) lid: vec3<u32>,
        @builtin(workgroup_id) wid: vec3<u32>) {
    let M = params.M;
    let N = params.N;
    let K = params.K;

    let tx = lid.x;  // 0..15
    let ty = lid.y;  // 0..15
    let tid = ty * 16u + tx;  // linear thread id 0..255

    // Base row/col for this workgroup's 64x64 output tile
    let wg_row = wid.y * 64u;
    let wg_col = wid.x * 64u;

    // Each thread accumulates a 4x4 block of outputs
    var c00: f32 = 0.0; var c01: f32 = 0.0; var c02: f32 = 0.0; var c03: f32 = 0.0;
    var c10: f32 = 0.0; var c11: f32 = 0.0; var c12: f32 = 0.0; var c13: f32 = 0.0;
    var c20: f32 = 0.0; var c21: f32 = 0.0; var c22: f32 = 0.0; var c23: f32 = 0.0;
    var c30: f32 = 0.0; var c31: f32 = 0.0; var c32: f32 = 0.0; var c33: f32 = 0.0;

    let num_tiles = (K + 15u) / 16u;

    for (var t: u32 = 0u; t < num_tiles; t++) {
        let k_off = t * 16u;

        // Cooperatively load sa[64][16] — 1024 elements, 4 per thread
        for (var i: u32 = 0u; i < 4u; i++) {
            let idx = tid * 4u + i;
            let r = idx / 16u;       // row within tile (0..63)
            let c = idx % 16u;       // col within tile (0..15)
            let gr = wg_row + r;     // global row
            let gc = k_off + c;      // global col
            if (gr < M && gc < K) {
                sa[idx] = A[gr * K + gc];
            } else {
                sa[idx] = 0.0;
            }
        }

        // Cooperatively load sb[16][64] — 1024 elements, 4 per thread
        for (var i: u32 = 0u; i < 4u; i++) {
            let idx = tid * 4u + i;
            let r = idx / 64u;       // row within tile (0..15)
            let c = idx % 64u;       // col within tile (0..63)
            let gr = k_off + r;      // global row
            let gc = wg_col + c;     // global col
            if (gr < K && gc < N) {
                sb[idx] = B[gr * N + gc];
            } else {
                sb[idx] = 0.0;
            }
        }

        workgroupBarrier();

        // Compute 4x4 output block per thread
        // Thread (tx, ty) computes rows [ty*4..ty*4+3] x cols [tx*4..tx*4+3]
        for (var k: u32 = 0u; k < 16u; k++) {
            // Load 4 values from A tile (column k, rows ty*4..ty*4+3)
            let a0 = sa[(ty * 4u + 0u) * 16u + k];
            let a1 = sa[(ty * 4u + 1u) * 16u + k];
            let a2 = sa[(ty * 4u + 2u) * 16u + k];
            let a3 = sa[(ty * 4u + 3u) * 16u + k];

            // Load 4 values from B tile (row k, cols tx*4..tx*4+3)
            let b0 = sb[k * 64u + tx * 4u + 0u];
            let b1 = sb[k * 64u + tx * 4u + 1u];
            let b2 = sb[k * 64u + tx * 4u + 2u];
            let b3 = sb[k * 64u + tx * 4u + 3u];

            // Outer product accumulation
            c00 += a0 * b0; c01 += a0 * b1; c02 += a0 * b2; c03 += a0 * b3;
            c10 += a1 * b0; c11 += a1 * b1; c12 += a1 * b2; c13 += a1 * b3;
            c20 += a2 * b0; c21 += a2 * b1; c22 += a2 * b2; c23 += a2 * b3;
            c30 += a3 * b0; c31 += a3 * b1; c32 += a3 * b2; c33 += a3 * b3;
        }

        workgroupBarrier();
    }

    // Write 4x4 output block
    let alpha = params.alpha;
    let or0 = wg_row + ty * 4u;
    let oc0 = wg_col + tx * 4u;

    if (or0 + 0u < M && oc0 + 0u < N) { C[(or0 + 0u) * N + oc0 + 0u] = alpha * c00; }
    if (or0 + 0u < M && oc0 + 1u < N) { C[(or0 + 0u) * N + oc0 + 1u] = alpha * c01; }
    if (or0 + 0u < M && oc0 + 2u < N) { C[(or0 + 0u) * N + oc0 + 2u] = alpha * c02; }
    if (or0 + 0u < M && oc0 + 3u < N) { C[(or0 + 0u) * N + oc0 + 3u] = alpha * c03; }

    if (or0 + 1u < M && oc0 + 0u < N) { C[(or0 + 1u) * N + oc0 + 0u] = alpha * c10; }
    if (or0 + 1u < M && oc0 + 1u < N) { C[(or0 + 1u) * N + oc0 + 1u] = alpha * c11; }
    if (or0 + 1u < M && oc0 + 2u < N) { C[(or0 + 1u) * N + oc0 + 2u] = alpha * c12; }
    if (or0 + 1u < M && oc0 + 3u < N) { C[(or0 + 1u) * N + oc0 + 3u] = alpha * c13; }

    if (or0 + 2u < M && oc0 + 0u < N) { C[(or0 + 2u) * N + oc0 + 0u] = alpha * c20; }
    if (or0 + 2u < M && oc0 + 1u < N) { C[(or0 + 2u) * N + oc0 + 1u] = alpha * c21; }
    if (or0 + 2u < M && oc0 + 2u < N) { C[(or0 + 2u) * N + oc0 + 2u] = alpha * c22; }
    if (or0 + 2u < M && oc0 + 3u < N) { C[(or0 + 2u) * N + oc0 + 3u] = alpha * c23; }

    if (or0 + 3u < M && oc0 + 0u < N) { C[(or0 + 3u) * N + oc0 + 0u] = alpha * c30; }
    if (or0 + 3u < M && oc0 + 1u < N) { C[(or0 + 3u) * N + oc0 + 1u] = alpha * c31; }
    if (or0 + 3u < M && oc0 + 2u < N) { C[(or0 + 3u) * N + oc0 + 2u] = alpha * c32; }
    if (or0 + 3u < M && oc0 + 3u < N) { C[(or0 + 3u) * N + oc0 + 3u] = alpha * c33; }
}
